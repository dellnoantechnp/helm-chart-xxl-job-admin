# Default values for canal-server.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  registry: ghcr.io
  repository: dellnoantechnp/canal-server
  # Overrides the image tag whose default is the chart appVersion.
  tag: "v0.0.1"
  ## Specify a imagePullPolicy
  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
  ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images
  ##
  pullPolicy: IfNotPresent
  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  ## e.g:
  ## pullSecrets:
  ##   - myRegistryKeySecretName
  ##
  pullSecrets: []

## @param nameOverride String to partially override common.names.fullname template (will maintain the release name)
##
nameOverride: ""
## @param fullnameOverride String to fully override common.names.fullname template
##
fullnameOverride: ""

## @param containerPorts.canal; container port to open for canal-server
## @param containerPorts.admin; container port to open for canal-server admin
## @param containerPorts.metrics; container port to open for canal-server metrics
##
containerPorts:
  canal: 11111
  admin: 11110
  metrics: 11112

service:
  ## @param service.type canal-server; service type
  ##
  type: ClusterIP
  ## @param service.ports.canal; Canal-server service port
  ## @param service.ports.admin; admin service port
  ## @param service.ports.metrics; metrics service port
  ##
  ports:
    canal: 11111
    admin: 11110
    metrics: 11112

## configure the canal-server detail
ServerConf:
  ## @param jvmFlags for canal-server process, privilege higher than heapSize.
  ##
  jvmFlags: ""
  ## @param heapOpts canal-server Java Heap size
  ##
  heapSize: 1024
  ## @param canalPortNumber specify canal-server listen tcp port number, for canal-client.
  ##
  canalPortNumber: "{{ .Values.containerPorts.canal }}"
  ## @param canalAdminPortNumber specify canal-server admin tcp port number, for canal-admin.
  ##
  canalAdminPortNumber: "{{ .Values.containerPorts.admin }}"
  ## @param canalAdminUser specify canal-server admin account username.
  ##
  canalAdminUser: admin
  ## @param canalAdminCiphertextPassword specify canal-server admin account password.
  ##
  canalAdminCiphertextPassword: admin
  ## @param canalMetricsPortNumber specify canal-server metrics tcp port number, for prometheus.
  ##
  canalMetricsPortNumber: "{{ .Values.containerPorts.metrics }}"
  ## @param canalServerMode specify canal server-mode, eg. tcp, kafka, rocketMQ, rabbitMQ, pulsarMQ
  ## 
  canalServerMode: tcp
InstanceConf:
  ## @param canal.instance.gtidon boolean, for instance gtid mode.
  ## @param canal.instance.mysql.slaveId.autoGenerate boolean, for auto generate instance serverID.
  ## @param canal.instance.mysql.slaveId.number int, for instance serverID.
  ##
  canal:
    instance:
      - name: example
        mysql:
          slaveId:
            autoGenerate: false
            number: 12345
        gtidon: false
        master:
          address: 127.0.0.1
        dbUsername: canal
        dbPassword: canal
        filter:
          regex: ".*\\..*"
          black:
            regex: "mysql\\.slave_.*"
      - name: futures
        mysql:
          slaveId:
            autoGenerate: false
            number: 12345
        gtidon: false
        master:
          address: 127.0.0.1
        dbUsername: canal
        dbPassword: canal
        filter:
          regex: ".*\\..*"
          black:
            regex: "mysql\\.slave_.*"

## configure canal repl source from mysql detail
ReplSourceConf:
  MySQL_REPL_address: 127.0.0.1
  MySQL_REPL_port: 3306
  MySQL_REPL_user: canal
  MySQL_REPL_password: canal_pass

## configure canal tsdb database by mysql detail
TsdbDBConf:
  enabled: true
  canal_tsdb_mysql_address: 127.0.0.1
  canal_tsdb_mysql_port: 3306
  canal_tsdb_db_name: canal_tsdb
  canal_tsdb_db_user: canal
  canal_tsdb_db_password: canal


serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

## @param extraEnvVars Extra environment variables to be set on canal-server container
## e.g:
## extraEnvVars:
##   - name: FOO
##     value: "bar"
##
extraEnvVars: []
## @param extraEnvVarsCM ConfigMap with extra environment variables
##
extraEnvVarsCM: ""
## @param extraEnvVarsSecret Secret with extra environment variables
##
extraEnvVarsSecret: ""

## @param command Default container command (useful when using custom images). Use array form
##
command: []
## @param args Default container args (useful when using custom images). Use array form
##
args: []

podAnnotations: {}

## Canal-server pod Security Context
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
## @param podSecurityContext.enabled Enable pod Security Context
## @param podSecurityContext.fsGroup Group ID for the container
##
podSecurityContext:
  enabled: false
  fsGroup: 1001

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
# runAsUser: 1000

## @section canal-server; deployment/statefulset parameters

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: canal.example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

## @param hostAliases canal-server; pod host aliases
## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
##
hostAliases: []

resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  ## Example:
  ## limits:
  ##    cpu: 250m
  ##    memory: 256Mi
  limits: {}
  ## Examples:
  ## requests:
  ##    cpu: 250m
  ##    memory: 256Mi
  requests: {}
  ##  cpu: 250m
  ##  memory: 256Mi

## Configure extra options for liveness probe
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
## @param livenessProbe.enabled Enable livenessProbe
## @param livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
## @param livenessProbe.periodSeconds Period seconds for livenessProbe
## @param livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
## @param livenessProbe.failureThreshold Failure threshold for livenessProbe
## @param livenessProbe.successThreshold Success threshold for livenessProbe
##
livenessProbe:
  enabled: true
  initialDelaySeconds: 10
  periodSeconds: 5
  timeoutSeconds: 5
  successThreshold: 1
  failureThreshold: 5
## Configure extra options for readiness probe
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
## @param readinessProbe.enabled Enable readinessProbe
## @param readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
## @param readinessProbe.periodSeconds Period seconds for readinessProbe
## @param readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
## @param readinessProbe.failureThreshold Failure threshold for readinessProbe
## @param readinessProbe.successThreshold Success threshold for readinessProbe
##
readinessProbe:
  enabled: true
  initialDelaySeconds: 10
  periodSeconds: 5
  timeoutSeconds: 1
  successThreshold: 1
  failureThreshold: 5
## Configure extra options for startupProbe probe
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
## @param startupProbe.enabled Enable startupProbe
## @param startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
## @param startupProbe.periodSeconds Period seconds for startupProbe
## @param startupProbe.timeoutSeconds Timeout seconds for startupProbe
## @param startupProbe.failureThreshold Failure threshold for startupProbe
## @param startupProbe.successThreshold Success threshold for startupProbe
##
startupProbe:
  enabled: false
  initialDelaySeconds: 0
  periodSeconds: 10
  timeoutSeconds: 5
  successThreshold: 1
  failureThreshold: 60
## @param customLivenessProbe Override default liveness probe
##
customLivenessProbe: {}
## @param customReadinessProbe Override default readiness probe
##
customReadinessProbe: {}
## @param customStartupProbe Override default startup probe
##
customStartupProbe: {}

## @param initContainers Add additional init containers to the Canal-server; pods
## e.g:
## initContainers:
##   - name: your-image-name
##     image: your-image
##     imagePullPolicy: Always
##     ports:
##       - name: portname
##         containerPort: 1234
##
initContainers: []
## @param sidecars Add additional sidecar containers to the Canal-server; pods
## e.g:
## sidecars:
##   - name: your-image-name
##     image: your-image
##     imagePullPolicy: Always
##     ports:
##       - name: portname
##         containerPort: 1234
##
sidecars: []

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}

## Zookeeper chart configuration
## https://github.com/bitnami/charts/blob/master/bitnami/zookeeper/values.yaml
##
zookeeper:
  ## @param zookeeper.enabled Switch to enable or disable the Zookeeper helm chart
  ##
  enabled: true
  auth:
    ## @param zookeeper.auth.enabled Enable Zookeeper auth
    ##
    enabled: false
    ## @param zookeeper.auth.clientUser User that will use Zookeeper clients to auth
    ##
    clientUser: ""
    ## @param zookeeper.auth.clientPassword Password that will use Zookeeper clients to auth
    ##
    clientPassword: ""
    ## @param zookeeper.auth.serverUsers Comma, semicolon or whitespace separated list of user to be created. Specify them as a string, for example: "user1,user2,admin"
    ##
    serverUsers: ""
    ## @param zookeeper.auth.serverPasswords Comma, semicolon or whitespace separated list of passwords to assign to users when created. Specify them as a string, for example: "pass4user1, pass4user2, pass4admin"
    ##
    serverPasswords: ""
## This value is only used when zookeeper.enabled is set to false
##
externalZookeeper:
  ## @param externalZookeeper.servers Server or list of external Zookeeper servers to use
  ##
  servers: []

config:
  canal: |
    # tcp bind ip
    canal.ip=
    # register ip to zookeeper
    canal.register.ip=
    canal.port="{{ .Values.ServerConf.canalPortNumber }}"
    canal.metrics.pull.port="{{ .Values.ServerConf.canalMetricsPortNumber }}"
    
    # canal instance user/passwd
    # canal.user = canal
    # canal.passwd = E3619321C1A937C46A0D8BD1DAC39F93B27D4458
    
    # canal admin config
    #canal.admin.manager = 127.0.0.1:8089
    canal.admin.port="{{ .Values.ServerConf.canalAdminPortNumber }}"
    canal.admin.user="{{ .Values.ServerConf.canalAdminUser }}"
    canal.admin.passwd=${CANAL_ADMIN_CIPHERTEXT_PASSWORD:4ACFE3202A5FF5CF467898FC58AAB1D615029441}
    
    # admin auto register
    #canal.admin.register.auto = true
    #canal.admin.register.cluster =
    #canal.admin.register.name =
    canal.zkServers=
    
    # flush data to zk
    canal.zookeeper.flush.period=1000
    canal.withoutNetty=false
    
    # tcp, kafka, rocketMQ, rabbitMQ, pulsarMQ
    canal.serverMode={{ .Values.ServerConf.canalServerMode}}
    
    # flush meta cursor/parse position to file
    canal.file.data.dir=${canal.conf.dir}
    canal.file.flush.period=1000
    
    ## memory store RingBuffer size, should be Math.pow(2,n)
    canal.instance.memory.buffer.size=16384
    ## memory store RingBuffer used memory unit size , default 1kb
    canal.instance.memory.buffer.memunit=1024
    
    ## meory store gets mode used MEMSIZE or ITEMSIZE
    canal.instance.memory.batch.mode=MEMSIZE
    canal.instance.memory.rawEntry=true
    
    ## detecing config
    canal.instance.detecting.enable=false
    #canal.instance.detecting.sql = insert into retl.xdual values(1,now()) on duplicate key update x=now()
    canal.instance.detecting.sql=select 1
    canal.instance.detecting.interval.time=3
    canal.instance.detecting.retry.threshold=3
    canal.instance.detecting.heartbeatHaEnable=false
    
    # support maximum transaction size, more than the size of the transaction will be cut into multiple transactions delivery
    canal.instance.transaction.size=1024
    
    # mysql fallback connected to new master should fallback times
    canal.instance.fallbackIntervalInSeconds=60
    
    # network config
    canal.instance.network.receiveBufferSize=16384
    canal.instance.network.sendBufferSize=16384
    canal.instance.network.soTimeout=30
    
    # binlog filter config
    canal.instance.filter.druid.ddl=true
    canal.instance.filter.query.dcl=false
    canal.instance.filter.query.dml=false
    canal.instance.filter.query.ddl=false
    canal.instance.filter.table.error=false
    canal.instance.filter.rows=false
    canal.instance.filter.transaction.entry=false
    canal.instance.filter.dml.insert=false
    canal.instance.filter.dml.update=false
    canal.instance.filter.dml.delete=false
    
    # binlog format/image check
    canal.instance.binlog.format=ROW,STATEMENT,MIXED
    canal.instance.binlog.image=FULL,MINIMAL,NOBLOB
    
    # binlog ddl isolation
    canal.instance.get.ddl.isolation=false
    
    # parallel parser config
    canal.instance.parser.parallel=true
    
    ## concurrent thread number, default 60% available processors, suggest not to exceed Runtime.getRuntime().availableProcessors()
    #canal.instance.parser.parallelThreadSize = 16
    
    ## disruptor ringbuffer size, must be power of 2
    canal.instance.parser.parallelBufferSize=256
    
    # table meta tsdb info
    canal.instance.tsdb.enable=true
    canal.instance.tsdb.dir=${canal.file.data.dir:../conf}/${canal.instance.destination:}
    #canal.instance.tsdb.url = jdbc:h2:${canal.instance.tsdb.dir}/h2;CACHE_SIZE=1000;MODE=MYSQL;
    canal.instance.tsdb.url=jdbc:mysql://${CANAL_TSDB_MYSQL_ADDRESS:127.0.0.1}:${CANAL_TSDB_MYSQL_PORT:3306}/${CANAL_TSDB_DB_NAME:canal_tsdb}?characterEncoding=utf-8&autoReconnect=true&rewriteBatchedStatements=true&serverTimezone=UTC
    canal.instance.tsdb.dbUsername=${CANAL_TSDB_USER:canal}
    canal.instance.tsdb.dbPassword=${CANAL_TSDB_PASSWORD:canal}
    
    # dump snapshot interval, default 24 hour
    canal.instance.tsdb.snapshot.interval=24
    
    # purge snapshot expire , default 360 hour(15 days)
    canal.instance.tsdb.snapshot.expire=360
    
    #####################################################
    #############     destinations          #############
    #####################################################
    canal.destinations=example
    # conf root dir
    canal.conf.dir=../conf
    
    # auto scan instance dir add/remove and start/stop instance
    canal.auto.scan=true
    canal.auto.scan.interval=5
    
    # set this value to 'true' means that when binlog pos not found, skip to latest.
    # WARN: pls keep 'false' in production env, or if you know what you want.
    canal.auto.reset.latest.pos.mode=false
    #canal.instance.tsdb.spring.xml = classpath:spring/tsdb/h2-tsdb.xml
    canal.instance.tsdb.spring.xml=classpath:spring/tsdb/mysql-tsdb.xml
    canal.instance.global.mode=spring
    canal.instance.global.lazy=false
    canal.instance.global.manager.address=${canal.admin.manager}
    #canal.instance.global.spring.xml = classpath:spring/memory-instance.xml
    canal.instance.global.spring.xml=classpath:spring/file-instance.xml
    #canal.instance.global.spring.xml = classpath:spring/default-instance.xml
    
    ##################################################
    #########         MQ Properties      #############
    ##################################################
    # aliyun ak/sk , support rds/mq
    canal.aliyun.accessKey=
    canal.aliyun.secretKey=
    canal.aliyun.uid=
    canal.mq.flatMessage=true
    canal.mq.canalBatchSize=50
    canal.mq.canalGetTimeout=100
    
    # Set this value to "cloud", if you want open message trace feature in aliyun.
    canal.mq.accessChannel=local
    canal.mq.database.hash=true
    canal.mq.send.thread.size=30
    canal.mq.build.thread.size=8
    
    ##################################################
    #########          Kafka             #############
    ##################################################
    kafka.bootstrap.servers=127.0.0.1:9092
    kafka.acks=all
    kafka.compression.type=none
    kafka.batch.size=16384
    kafka.linger.ms=1
    kafka.max.request.size=1048576
    kafka.buffer.memory=33554432
    kafka.max.in.flight.requests.per.connection=1
    kafka.retries=0
    kafka.kerberos.enable=false
    kafka.kerberos.krb5.file="../conf/kerberos/krb5.conf"
    kafka.kerberos.jaas.file="../conf/kerberos/jaas.conf"
    
    ##################################################
    #########         RocketMQ           #############
    ##################################################
    rocketmq.producer.group=test
    rocketmq.enable.message.trace=false
    rocketmq.customized.trace.topic=
    rocketmq.namespace=
    rocketmq.namesrv.addr=127.0.0.1:9876
    rocketmq.retry.times.when.send.failed=0
    rocketmq.vip.channel.enabled=false
    rocketmq.tag=
    
    ##################################################
    #########         RabbitMQ           #############
    ##################################################
    rabbitmq.host=
    rabbitmq.virtual.host=
    rabbitmq.exchange=
    rabbitmq.username=
    rabbitmq.password=
    rabbitmq.deliveryMode=
    
    ##################################################
    #########           Pulsar           #############
    ##################################################
    pulsarmq.serverUrl=
    pulsarmq.roleToken=
    pulsarmq.topicTenantPrefix=
  instance: |
    #################################################
    ## mysql serverId , v1.0.26+ will autoGen
    {{- if not .Values.InstanceConf.canal.instance.mysql.salveId.autoGenerate }}
    #canal.instance.mysql.slaveId=
    {{- else }}
    canal.instance.mysql.slaveId={{ .Values.InstanceConf.canal.instance.mysql.salveId.number }}
    {{- end }}
    # enable gtid use true/false
    canal.instance.gtidon="{{ .Values.InstanceConf.canal.instance.gtidon }}"

    # position info
    canal.instance.master.address={{ .Values.InstanceConf.canal.instance.master.address }}
    canal.instance.master.journal.name=
    canal.instance.master.position=
    canal.instance.master.timestamp=
    canal.instance.master.gtid=

    # rds oss binlog
    canal.instance.rds.accesskey=
    canal.instance.rds.secretkey=
    canal.instance.rds.instanceId=

    # table meta tsdb info
    canal.instance.tsdb.enable=true
    #canal.instance.tsdb.url=jdbc:mysql://127.0.0.1:3306/canal_tsdb?characterEncoding=utf-8&autoReconnect=true&rewriteBatchedStatements=true&serverTimezone=UTC
    #canal.instance.tsdb.dbUsername=canal
    #canal.instance.tsdb.dbPassword=canal
    #canal.instance.standby.address =
    #canal.instance.standby.journal.name =
    #canal.instance.standby.position =
    #canal.instance.standby.timestamp =
    #canal.instance.standby.gtid=

    # username/password
    canal.instance.dbUsername={{ .Values.InstanceConf.canal.instance.dbUsername }}
    canal.instance.dbPassword={{ .Values.InstanceConf.canal.instance.dbPassword }}
    canal.instance.connectionCharset=UTF-8

    # enable druid Decrypt database password
    canal.instance.enableDruid=false
    #canal.instance.pwdPublicKey=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBALK4BUxdDltRRE5/zXpVEVPUgunvscYFtEip3pmLlhrWpacX7y7GCMo2/JM6LeHmiiNdH1FWgGCpUfircSwlWKUCAwEAAQ==

    # table regex
    canal.instance.filter.regex={{ .Values.InstanceConf.canal.instance.filter.regex }}

    # table black regex
    canal.instance.filter.black.regex={{ .Values.InstanceConf.canal.instance.filter.black.regex }}

    # table field filter(format: schema1.tableName1:field1/field2,schema2.tableName2:field1/field2)
    #canal.instance.filter.field=test1.t_product:id/subject/keywords,test2.t_company:id/name/contact/ch

    # table field black filter(format: schema1.tableName1:field1/field2,schema2.tableName2:field1/field2)
    #canal.instance.filter.black.field=test1.t_product:subject/product_image,test2.t_company:id/name/contact/ch

    # mq config
    canal.mq.topic=example

    # dynamic topic route by schema or table regex
    #canal.mq.dynamicTopic=mytest1.user,topic2:mytest2\\..*,.*\\..*
    canal.mq.partition=0

    # hash partition config
    #canal.mq.enableDynamicQueuePartition=false
    #canal.mq.partitionsNum=3
    #canal.mq.dynamicTopicPartitionNum=test.*:4,mycanal:6
    #canal.mq.partitionHash=test.table:id^name,.*\\..*
    #################################################