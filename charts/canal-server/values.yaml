# Default values for canal-server.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: ghcr.io/dellnoantechnp/canal-server
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: "v0.0.1"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""



## configure the canal-server detail
ServerConf:
  ## @param jvmFlags for canal-server process, privilege higher than heapSize.
  ##
  jvmFlags: ""
  ## @param heapOpts canal-server Java Heap size
  ##
  heapSize: 1024
  ## @param canalPortNumber specify canal-server listen tcp port number, for canal-client.
  ##
  canalPortNumber: 11111
  ## @param canalAdminPortNumber specify canal-server admin tcp port number, for canal-admin.
  ##
  canalAdminPortNumber: 11110
  ## @param canalAdminUser specify canal-server admin account username.
  ##
  canalAdminUser: admin
  ## @param canalAdminCiphertextPassword specify canal-server admin account password.
  ##
  canalAdminCiphertextPassword: admin
  ## @param canalMetricsPortNumber specify canal-server metrics tcp port number, for prometheus.
  ##
  canalMetricsPortNumber: 11112
  ## @param canalServerMode specify canal server-mode, eg. tcp, kafka, rocketMQ, rabbitMQ, pulsarMQ
  ## 
  canalServerMode: tcp

## configure canal repl source from mysql detail
ReplSourceConf:
  MySQL_REPL_address: 127.0.0.1
  MySQL_REPL_port: 3306
  MySQL_REPL_user: canal
  MySQL_REPL_password: canal_pass

## configure canal tsdb database by mysql detail
TsdbDBConf:
  canal_tsdb_mysql_address: 127.0.0.1
  canal_tsdb_mysql_port: 3306
  canal_tsdb_db_name: canal_tsdb
  canal_tsdb_db_user: canal
  canal_tsdb_db_password: canal


serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

config:
  canal: |
    # tcp bind ip
    canal.ip=
    # register ip to zookeeper
    canal.register.ip=
    canal.port="{{ .Values.ServerConf.canalPortNumber }}"
    canal.metrics.pull.port="{{ .Values.ServerConf.canalMetricsPortNumber }}"
    
    # canal instance user/passwd
    # canal.user = canal
    # canal.passwd = E3619321C1A937C46A0D8BD1DAC39F93B27D4458
    
    # canal admin config
    #canal.admin.manager = 127.0.0.1:8089
    canal.admin.port="{{ .Values.ServerConf.canalAdminPortNumber }}"
    canal.admin.user="{{ .Values.ServerConf.canalAdminUser }}"
    canal.admin.passwd=${CANAL_ADMIN_CIPHERTEXT_PASSWORD:4ACFE3202A5FF5CF467898FC58AAB1D615029441}
    
    # admin auto register
    #canal.admin.register.auto = true
    #canal.admin.register.cluster =
    #canal.admin.register.name =
    canal.zkServers=
    
    # flush data to zk
    canal.zookeeper.flush.period=1000
    canal.withoutNetty=false
    
    # tcp, kafka, rocketMQ, rabbitMQ, pulsarMQ
    canal.serverMode={{ .Values.ServerConf.canalServerMode}}
    
    # flush meta cursor/parse position to file
    canal.file.data.dir=${canal.conf.dir}
    canal.file.flush.period=1000
    
    ## memory store RingBuffer size, should be Math.pow(2,n)
    canal.instance.memory.buffer.size=16384
    ## memory store RingBuffer used memory unit size , default 1kb
    canal.instance.memory.buffer.memunit=1024
    
    ## meory store gets mode used MEMSIZE or ITEMSIZE
    canal.instance.memory.batch.mode=MEMSIZE
    canal.instance.memory.rawEntry=true
    
    ## detecing config
    canal.instance.detecting.enable=false
    #canal.instance.detecting.sql = insert into retl.xdual values(1,now()) on duplicate key update x=now()
    canal.instance.detecting.sql=select 1
    canal.instance.detecting.interval.time=3
    canal.instance.detecting.retry.threshold=3
    canal.instance.detecting.heartbeatHaEnable=false
    
    # support maximum transaction size, more than the size of the transaction will be cut into multiple transactions delivery
    canal.instance.transaction.size=1024
    
    # mysql fallback connected to new master should fallback times
    canal.instance.fallbackIntervalInSeconds=60
    
    # network config
    canal.instance.network.receiveBufferSize=16384
    canal.instance.network.sendBufferSize=16384
    canal.instance.network.soTimeout=30
    
    # binlog filter config
    canal.instance.filter.druid.ddl=true
    canal.instance.filter.query.dcl=false
    canal.instance.filter.query.dml=false
    canal.instance.filter.query.ddl=false
    canal.instance.filter.table.error=false
    canal.instance.filter.rows=false
    canal.instance.filter.transaction.entry=false
    canal.instance.filter.dml.insert=false
    canal.instance.filter.dml.update=false
    canal.instance.filter.dml.delete=false
    
    # binlog format/image check
    canal.instance.binlog.format=ROW,STATEMENT,MIXED
    canal.instance.binlog.image=FULL,MINIMAL,NOBLOB
    
    # binlog ddl isolation
    canal.instance.get.ddl.isolation=false
    
    # parallel parser config
    canal.instance.parser.parallel=true
    
    ## concurrent thread number, default 60% available processors, suggest not to exceed Runtime.getRuntime().availableProcessors()
    #canal.instance.parser.parallelThreadSize = 16
    
    ## disruptor ringbuffer size, must be power of 2
    canal.instance.parser.parallelBufferSize=256
    
    # table meta tsdb info
    canal.instance.tsdb.enable=true
    canal.instance.tsdb.dir=${canal.file.data.dir:../conf}/${canal.instance.destination:}
    #canal.instance.tsdb.url = jdbc:h2:${canal.instance.tsdb.dir}/h2;CACHE_SIZE=1000;MODE=MYSQL;
    canal.instance.tsdb.url=jdbc:mysql://${CANAL_TSDB_MYSQL_ADDRESS:127.0.0.1}:${CANAL_TSDB_MYSQL_PORT:3306}/${CANAL_TSDB_DB_NAME:canal_tsdb}?characterEncoding=utf-8&autoReconnect=true&rewriteBatchedStatements=true&serverTimezone=UTC
    canal.instance.tsdb.dbUsername=${CANAL_TSDB_USER:canal}
    canal.instance.tsdb.dbPassword=${CANAL_TSDB_PASSWORD:canal}
    
    # dump snapshot interval, default 24 hour
    canal.instance.tsdb.snapshot.interval=24
    
    # purge snapshot expire , default 360 hour(15 days)
    canal.instance.tsdb.snapshot.expire=360
    
    #####################################################
    #############     destinations          #############
    #####################################################
    canal.destinations=example
    # conf root dir
    canal.conf.dir=../conf
    
    # auto scan instance dir add/remove and start/stop instance
    canal.auto.scan=true
    canal.auto.scan.interval=5
    
    # set this value to 'true' means that when binlog pos not found, skip to latest.
    # WARN: pls keep 'false' in production env, or if you know what you want.
    canal.auto.reset.latest.pos.mode=false
    #canal.instance.tsdb.spring.xml = classpath:spring/tsdb/h2-tsdb.xml
    canal.instance.tsdb.spring.xml=classpath:spring/tsdb/mysql-tsdb.xml
    canal.instance.global.mode=spring
    canal.instance.global.lazy=false
    canal.instance.global.manager.address=${canal.admin.manager}
    #canal.instance.global.spring.xml = classpath:spring/memory-instance.xml
    canal.instance.global.spring.xml=classpath:spring/file-instance.xml
    #canal.instance.global.spring.xml = classpath:spring/default-instance.xml
    
    ##################################################
    #########         MQ Properties      #############
    ##################################################
    # aliyun ak/sk , support rds/mq
    canal.aliyun.accessKey=
    canal.aliyun.secretKey=
    canal.aliyun.uid=
    canal.mq.flatMessage=true
    canal.mq.canalBatchSize=50
    canal.mq.canalGetTimeout=100
    
    # Set this value to "cloud", if you want open message trace feature in aliyun.
    canal.mq.accessChannel=local
    canal.mq.database.hash=true
    canal.mq.send.thread.size=30
    canal.mq.build.thread.size=8
    
    ##################################################
    #########          Kafka             #############
    ##################################################
    kafka.bootstrap.servers=127.0.0.1:9092
    kafka.acks=all
    kafka.compression.type=none
    kafka.batch.size=16384
    kafka.linger.ms=1
    kafka.max.request.size=1048576
    kafka.buffer.memory=33554432
    kafka.max.in.flight.requests.per.connection=1
    kafka.retries=0
    kafka.kerberos.enable=false
    kafka.kerberos.krb5.file="../conf/kerberos/krb5.conf"
    kafka.kerberos.jaas.file="../conf/kerberos/jaas.conf"
    
    ##################################################
    #########         RocketMQ           #############
    ##################################################
    rocketmq.producer.group=test
    rocketmq.enable.message.trace=false
    rocketmq.customized.trace.topic=
    rocketmq.namespace=
    rocketmq.namesrv.addr=127.0.0.1:9876
    rocketmq.retry.times.when.send.failed=0
    rocketmq.vip.channel.enabled=false
    rocketmq.tag=
    
    ##################################################
    #########         RabbitMQ           #############
    ##################################################
    rabbitmq.host=
    rabbitmq.virtual.host=
    rabbitmq.exchange=
    rabbitmq.username=
    rabbitmq.password=
    rabbitmq.deliveryMode=
    
    ##################################################
    #########           Pulsar           #############
    ##################################################
    pulsarmq.serverUrl=
    pulsarmq.roleToken=
    pulsarmq.topicTenantPrefix=

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}
